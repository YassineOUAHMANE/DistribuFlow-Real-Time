apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: spark-client

spec:
  serviceName: "spark-client-service"
  replicas: 1
  selector:
    matchLabels:
      app: spark-client

  template:
    metadata:
      labels:
        app: spark-client
    spec:
      containers:
        - name: spark-client
          image: rabii10/spark-image:v2
          imagePullPolicy: IfNotPresent

          securityContext:
            runAsUser: 0
            runAsGroup: 0

          env:
            - name: SPARK_LOG_LEVEL
              value: "WARN"

          command: ["/bin/bash","-c"]
          args:
            - |
              set -ex

              # Outils utiles dans le pod
              apt-get update
              apt-get install -y nano iputils-ping dnsutils
              apt-get clean
              rm -rf /var/lib/apt/lists/*

              # ðŸ‘‰ Installation de joblib (et autres libs Python si tu veux)
              # Si ton image a dÃ©jÃ  pip, Ã§a marche direct. Sinon, ajoute son install dans le Dockerfile.
              python3 -m pip install --no-cache-dir pandas joblib numpy

              # Garder le pod vivant pour lancer spark-submit Ã  la main
              sleep infinity

          ports:
            - containerPort: 8081
          resources:
            requests:
              cpu: "500m"
              memory: "512Mi"
            limits:
              cpu: "1"
              memory: "1Gi"

---
apiVersion: v1
kind: Service
metadata:
  name: spark-client-service
spec:
  clusterIP: None
  selector:
    app: spark-client
  ports:
    - port: 8081
      targetPort: 8081
      protocol: TCP
