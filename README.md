# D√©ploiment sur GCP

Ce projet d√©ploie une architecture compl√®te de traitement de donn√©es en temps r√©el sur Google Cloud Platform (GCP). Il utilise **Terraform** pour l'infrastructure, **Ansible** pour la configuration, et **Kubernetes** pour l'orchestration des conteneurs (Kafka & Spark).

---

## Partie 1 : Configuration Locale

Ces √©tapes provisionnent les VMs et installent les d√©pendances logicielles.

### 1. D√©ploiement de l'infrastructure (Terraform)
```bash
cd infra/terraform
terraform apply
# Tapez 'yes' pour confirmer.
# ‚ö†Ô∏è IMPORTANT : Notez les IPs affich√©es √† la fin (Gateway & Master).
```
###¬†2. Configuration des machines (Ansible)

Installation de Docker, Kubernetes et des outils r√©seaux.

```bash
cd ../config
# La variable ANSIBLE_HOST_KEY_CHECKING=False √©vite les blocages li√©s aux nouvelles cl√©s SSH
ANSIBLE_HOST_KEY_CHECKING=False ansible-playbook -i inventory.ini playbook.yml
```

### 3. Pr√©paration SSH & Transfert de fichiers

Utilisation de l'agent SSH pour faciliter le passage par la Gateway.

```bash
# Charger la cl√© dans l'agent
eval $(ssh-agent -s)
ssh-add config/id_rsa_gcp

# Copier le projet vers le Master (via la Gateway)
# Remplacer <IP_GATEWAY> et <IP_MASTER> par les vraies valeurs
scp -r -J ubuntu@<IP_GATEWAY> apache_kafka/ python_producer/ scripts/ spark/ ubuntu@<IP_MASTER>:~/project
```

### 4. Connexion au Master

```bash
ssh -A -J ubuntu@<IP_GATEWAY> ubuntu@<IP_MASTER>
```

## Partie 2 : Configuration du Cluster (Sur le Master)

Toutes les commandes suivantes s'ex√©cutent dans le terminal du Master.

```bash
cd ~/project
```

### 1. Initialisation du Stockage & R√©seau

Indispensable pour que Kafka puisse stocker ses donn√©es et que les pods communiquent.

```bash
# Installer le provisionneur de stockage local
kubectl apply -f [https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml](https://raw.githubusercontent.com/rancher/local-path-provisioner/master/deploy/local-path-storage.yaml)

# D√©finir ce stockage comme "default"
kubectl patch storageclass local-path -p '{"metadata": {"annotations":{"storageclass.kubernetes.io/is-default-class":"true"}}}'

# Red√©marrer le DNS (Correctif Firewall GCP)
kubectl delete pod -n kube-system -l k8s-app=kube-dns
```

###¬†2. D√©ploiement des Services

Apache Kafka :

```bash
kubectl apply -f apache_kafka/kafka_controller_statefulset.yaml
kubectl apply -f apache_kafka/kafka_broker_statefulset.yaml
```

Apache Spark :

```bash
kubectl apply -f spark/spark_master_deployment.yaml
kubectl apply -f spark/spark_worker_deployment.yaml
kubectl apply -f spark/spark_client_statefulset.yaml
```

Producteur de Donn√©es :

```bash
kubectl apply -f app-data/python_producer/producer_pod.yaml
```

## Partie 3 : Pr√©paration des Jobs

Injection des scripts Python et des mod√®les ML dans les Pods actifs.
###1. Configuration du Client Spark

```bash
kubectl cp spark/spark_submit.sh spark-client-0:/opt/spark/work-dir/spark_submit.sh
kubectl cp spark/spark_job.py spark-client-0:/opt/spark/work-dir/spark_job.py
kubectl cp spark/model_utils.py spark-client-0:/opt/spark/work-dir/model_utils.py
kubectl cp spark/pretrained_models/ spark-client-0:/opt/spark/work-dir/pretrained_models/
```

### 2. Configuration du Producteur

```bash
kubectl cp python_producer/producer.py python-producer:/producer.py
```

## Partie 4 : Ex√©cution (D√©mo)

Ouvrez deux terminaux connect√©s au Master pour visualiser le flux en temps r√©el.

**Terminal A :** Lancer le Traitement Spark (Consommateur)

Ce job va lire les donn√©es depuis Kafka et appliquer le mod√®le de pr√©diction.

```bash
kubectl exec -it spark-client-0 -- /bin/bash /opt/spark/work-dir/spark_submit.sh
```

**Terminal B :** Lancer la Production de Donn√©es

Ce script g√©n√®re des logs et les envoie dans Kafka.

```bash
kubectl exec -it python-producer -- python3 /producer.py
```

## üöë D√©pannage

Si les Pods Kafka restent bloqu√©s en statut Pending, lancez un nettoyage complet des volumes :

```bash
kubectl delete pod kafka-broker-0 kafka-controller-0
kubectl delete pvc --all
# Les pods red√©marreront automatiquement avec le nouveau stockage.
```


